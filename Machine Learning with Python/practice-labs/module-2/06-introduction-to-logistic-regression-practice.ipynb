{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47aa283",
   "metadata": {},
   "source": [
    "## Key Concepts and Glossary References\n",
    "\n",
    "See: `Machine Learning with Python/notes/glossary-module-2.md`\n",
    "- Logistic Regression\n",
    "- Sigmoid Function (Logistic Function)\n",
    "- Odds, Log Odds (Logit), Odds Ratio\n",
    "- Decision Boundary, Threshold\n",
    "- Class Imbalance\n",
    "- Probability Calibration\n",
    "\n",
    "We will reference these terms inline in comments where used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac972c24",
   "metadata": {},
   "source": [
    "## Run Me First (Setup)\n",
    "This cell installs/imports dependencies, sets seeds, and configures plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports: core scientific stack\n",
    "import numpy as np  # numerical computing (vectors, matrices)\n",
    "import pandas as pd  # data manipulation with DataFrames\n",
    "\n",
    "# Imports: plotting libraries\n",
    "import matplotlib.pyplot as plt  # plotting primitives\n",
    "import seaborn as sns  # statistical visualizations built on matplotlib\n",
    "\n",
    "# Imports: scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split  # split data into train/test (see glossary: Train/Test Split)\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # encode categories; scale numeric features (see glossary: Feature Scaling)\n",
    "from sklearn.compose import ColumnTransformer  # apply different transforms to columns\n",
    "from sklearn.pipeline import Pipeline  # chain preprocessing + model in one object (see glossary: Pipeline)\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression classifier (see glossary: Logistic Regression)\n",
    "from sklearn.metrics import (  # evaluation metrics for classification\n",
    "    accuracy_score, precision_score, recall_score, f1_score,  # core metrics\n",
    "    roc_auc_score, roc_curve, precision_recall_curve, confusion_matrix, classification_report  # curves + diagnostics\n",
    ")\n",
    "from sklearn.calibration import calibration_curve  # probability calibration curve (see glossary: Probability Calibration)\n",
    "from sklearn.ensemble import RandomForestClassifier  # alternative model for comparison\n",
    "\n",
    "# Configure deterministic behavior\n",
    "np.random.seed(42)  # set global NumPy seed for reproducibility\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')  # use a modern seaborn-compatible style\n",
    "sns.set_palette('deep')  # set a color palette for consistency\n",
    "%matplotlib inline  # render plots inline in the notebook\n",
    "\n",
    "# Display options for pandas\n",
    "pd.set_option('display.max_columns', None)  # show all columns when printing DataFrames\n",
    "pd.set_option('display.precision', 3)  # set numeric precision for readability\n",
    "\n",
    "# Print library versions for reproducibility\n",
    "print('✅ Setup complete!')  # setup confirmation\n",
    "print(f'NumPy: {np.__version__}')  # report NumPy version\n",
    "print(f'pandas: {pd.__version__}')  # report pandas version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e41137",
   "metadata": {},
   "source": [
    "## Generate Synthetic Telecom Churn Dataset\n",
    "We create a realistic binary classification dataset with meaningful features.\n",
    "- Industry context: Telecommunications (contracts, monthly charges, support calls)\n",
    "- Target: `churn` (1 = left, 0 = stayed)\n",
    "- Includes categorical and numeric features, correlations, and mild outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set sample size for the synthetic dataset (see instruction: 50-200 rows)\n",
    "n = 150  # number of customers to simulate\n",
    "\n",
    "# Generate numeric features with realistic ranges\n",
    "age = np.random.randint(18, 80, size=n)  # customer age in years\n",
    "tenure_months = np.random.randint(1, 72, size=n)  # months with company (1-71)\n",
    "monthly_charges = np.random.uniform(20, 120, size=n).round(2)  # monthly fee in dollars\n",
    "support_calls = np.random.poisson(lam=1.5, size=n)  # count of support tickets last 3 months\n",
    "\n",
    "# Generate a categorical feature: contract type (monthly, annual, two_year)\n",
    "contract_type = np.random.choice(['monthly', 'annual', 'two_year'], size=n, p=[0.6, 0.3, 0.1])  # category with probabilities\n",
    "\n",
    "# Introduce mild outliers for realism (a few high-charge or high-support customers)\n",
    "outlier_idx = np.random.choice(np.arange(n), size=5, replace=False)  # choose some indices for outliers\n",
    "monthly_charges[outlier_idx] *= 1.8  # increase charges by 80% for selected customers\n",
    "support_calls[outlier_idx] += 4  # add extra support calls for the same customers\n",
    "\n",
    "# Define true underlying coefficients to compute log-odds (see glossary: Log Odds / Logit)\n",
    "beta_0 = -2.0  # intercept term shifts overall churn prevalence\n",
    "beta_age = 0.012  # older customers slightly more likely to churn (hypothetical)\n",
    "beta_tenure = -0.03  # longer tenure reduces churn odds\n",
    "beta_monthly = 0.02  # higher monthly charges increase churn odds\n",
    "beta_support = 0.18  # more support calls increase churn odds\n",
    "\n",
    "# Map categorical effects to coefficients (reference: 'annual' as baseline)\n",
    "beta_contract = {  # contract type contributions to log-odds\n",
    "    'annual': 0.0,       # baseline\n",
    "    'monthly': 0.8,      # monthly contracts churn more\n",
    "    'two_year': -0.5     # longer contracts churn less\n",
    "}\n",
    "\n",
    "# Compute linear score z for each customer (z = θ^T x)\n",
    "z = (  # linear combination of features before sigmoid (see glossary: Sigmoid Function)\n",
    "    beta_0\n",
    "    + beta_age * age\n",
    "    + beta_tenure * tenure_months\n",
    "    + beta_monthly * monthly_charges\n",
    "    + beta_support * support_calls\n",
    "    + np.array([beta_contract[c] for c in contract_type])\n",
    ")\n",
    "\n",
    "# Convert z to probabilities via sigmoid: p = 1 / (1 + exp(-z)) (see glossary: Probability)\n",
    "p = 1 / (1 + np.exp(-z))  # predicted probability of churn for each customer\n",
    "\n",
    "# Sample binary target from Bernoulli distribution using probability p (see glossary: Binary Classification)\n",
    "churn = np.random.binomial(n=1, p=p, size=n)  # 1 = churn, 0 = stay\n",
    "\n",
    "# Assemble DataFrame\n",
    "df = pd.DataFrame({  # create a table of all features and target\n",
    "    'age': age,\n",
    "    'tenure_months': tenure_months,\n",
    "    'monthly_charges': monthly_charges,\n",
    "    'support_calls': support_calls,\n",
    "    'contract_type': contract_type,\n",
    "    'churn': churn\n",
    "})\n",
    "\n",
    "# Show basic dataset info\n",
    "print('✅ Synthetic dataset created')  # confirmation message\n",
    "print(df.head())  # preview first rows\n",
    "print(df['churn'].value_counts(normalize=True).rename('class_ratio'))  # show class balance (see glossary: Class Imbalance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce0b6e",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "- `age`: Customer age in years (numeric)\n",
    "- `tenure_months`: Number of months with the company (numeric)\n",
    "- `monthly_charges`: Monthly fee in USD (numeric)\n",
    "- `support_calls`: Number of support tickets in last 3 months (numeric)\n",
    "- `contract_type`: Contract category (categorical: monthly, annual, two_year)\n",
    "- `churn`: Target label (binary: 1 = churned, 0 = stayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81660067",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "We explore distributions, relationships, and class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be439915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View basic structure\n",
    "print(df.shape)  # print number of rows and columns\n",
    "print(df.dtypes)  # print data types of each column\n",
    "display(df.describe(include='all'))  # summary stats for numeric + categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eab700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of numeric features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))  # create a 2x2 grid of subplots\n",
    "sns.histplot(df['age'], bins=20, ax=axes[0, 0])  # histogram of age\n",
    "axes[0, 0].set_title('Age Distribution')  # add title\n",
    "sns.histplot(df['tenure_months'], bins=20, ax=axes[0, 1])  # histogram of tenure\n",
    "axes[0, 1].set_title('Tenure (Months)')  # add title\n",
    "sns.histplot(df['monthly_charges'], bins=20, ax=axes[1, 0])  # histogram of charges\n",
    "axes[1, 0].set_title('Monthly Charges ($)')  # add title\n",
    "sns.histplot(df['support_calls'], bins=15, ax=axes[1, 1])  # histogram of support calls\n",
    "axes[1, 1].set_title('Support Calls (3 mo)')  # add title\n",
    "plt.tight_layout()  # adjust layout to prevent overlap\n",
    "plt.show()  # render the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize churn by contract_type (categorical vs target)\n",
    "plt.figure(figsize=(6, 4))  # set figure size\n",
    "sns.barplot(x='contract_type', y='churn', data=df, estimator=np.mean)  # mean churn rate per category\n",
    "plt.title('Churn Rate by Contract Type')  # add title\n",
    "plt.ylabel('Mean Churn Rate')  # label y-axis\n",
    "plt.show()  # render plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102ecef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numeric features vs churn (see glossary: Correlation)\n",
    "corr = df[['age', 'tenure_months', 'monthly_charges', 'support_calls', 'churn']].corr()  # compute correlations\n",
    "plt.figure(figsize=(6, 4))  # set figure size\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt='.2f')  # heatmap with annotations\n",
    "plt.title('Correlation Matrix')  # add title\n",
    "plt.show()  # render heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30769b05",
   "metadata": {},
   "source": [
    "## Implement Logistic Regression (scikit-learn)\n",
    "We build a preprocessing + model pipeline, fit, and evaluate with multiple metrics.\n",
    "(See glossary: Logistic Regression, Threshold, ROC-AUC, Precision/Recall.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(columns=['churn'])  # all independent variables\n",
    "y = df['churn']  # binary target (0/1)\n",
    "\n",
    "# Identify column types for preprocessing\n",
    "num_cols = ['age', 'tenure_months', 'monthly_charges', 'support_calls']  # numeric features\n",
    "cat_cols = ['contract_type']  # categorical features\n",
    "\n",
    "# Build transformers\n",
    "numeric_pipe = Pipeline([  # numeric pipeline\n",
    "    ('scaler', StandardScaler())  # scale numeric features (helps optimization)\n",
    "])\n",
    "categorical_pipe = Pipeline([  # categorical pipeline\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))  # one-hot encode categories\n",
    "])\n",
    "\n",
    "# ColumnTransformer applies each pipeline to respective columns\n",
    "preprocess = ColumnTransformer([  # assemble preprocessing steps\n",
    "    ('num', numeric_pipe, num_cols),  # numeric to scaler\n",
    "    ('cat', categorical_pipe, cat_cols)  # categorical to OHE\n",
    "])\n",
    "\n",
    "# Build full pipeline with Logistic Regression classifier\n",
    "clf = Pipeline([  # model pipeline\n",
    "    ('prep', preprocess),  # preprocessing step\n",
    "    ('lr', LogisticRegression(max_iter=1000, class_weight='balanced'))  # use class_weight to counter imbalance\n",
    "])\n",
    "\n",
    "# Create stratified train/test split for fair evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(  # split dataset\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42  # keep class ratio consistent across splits\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)  # train pipeline on training data\n",
    "\n",
    "# Predict probabilities and classes on test data\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]  # probability of class 1 (churn)\n",
    "y_pred = (y_proba >= 0.5).astype(int)  # apply default threshold 0.5 (see glossary: Threshold)\n",
    "\n",
    "# Compute metrics\n",
    "acc = accuracy_score(y_test, y_pred)  # accuracy\n",
    "prec = precision_score(y_test, y_pred)  # precision\n",
    "rec = recall_score(y_test, y_pred)  # recall\n",
    "f1 = f1_score(y_test, y_pred)  # F1-score\n",
    "auc = roc_auc_score(y_test, y_proba)  # ROC-AUC using probabilities\n",
    "\n",
    "# Display metric summary\n",
    "print(f'Accuracy: {acc:.3f}')  # print accuracy\n",
    "print(f'Precision: {prec:.3f}')  # print precision\n",
    "print(f'Recall: {rec:.3f}')  # print recall\n",
    "print(f'F1-score: {f1:.3f}')  # print f1\n",
    "print(f'ROC-AUC: {auc:.3f}')  # print ROC-AUC\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)  # 2x2 confusion matrix\n",
    "print('Confusion Matrix:\n",
    "', cm)  # show counts of TP, TN, FP, FN\n",
    "\n",
    "# Detailed classification report\n",
    "print('\n",
    "Classification Report\n",
    "')  # header\n",
    "print(classification_report(y_test, y_pred, digits=3))  # precision/recall/F1 per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773171a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC and Precision-Recall curves for threshold analysis\n",
    "fpr, tpr, roc_thresholds = roc_curve(y_test, y_proba)  # ROC curve data\n",
    "precisions, recalls, pr_thresholds = precision_recall_curve(y_test, y_proba)  # PR curve data\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))  # two side-by-side plots\n",
    "# ROC curve\n",
    "axes[0].plot(fpr, tpr, label=f'AUC = {auc:.3f}')  # plot ROC line with AUC\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', label='Chance')  # diagonal baseline\n",
    "axes[0].set_title('ROC Curve')  # add title\n",
    "axes[0].set_xlabel('False Positive Rate')  # x-label\n",
    "axes[0].set_ylabel('True Positive Rate')  # y-label\n",
    "axes[0].legend()  # show legend\n",
    "# Precision-Recall curve\n",
    "axes[1].plot(recalls, precisions)  # PR curve plot\n",
    "axes[1].set_title('Precision-Recall Curve')  # add title\n",
    "axes[1].set_xlabel('Recall')  # x-label\n",
    "axes[1].set_ylabel('Precision')  # y-label\n",
    "plt.tight_layout()  # adjust layout\n",
    "plt.show()  # render the plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a20e005",
   "metadata": {},
   "source": [
    "## Manual Sigmoid + Log Loss on a Mini-batch\n",
    "We demonstrate the core math: linear score z, sigmoid p, and binary cross-entropy (log loss).\n",
    "(See glossary: Sigmoid Function, Log Loss.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3206462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a small subset for manual demonstration\n",
    "mini = df.sample(5, random_state=1)  # pick 5 random rows for a mini example\n",
    "\n",
    "# Build a simple numeric-only linear score using a few standardized features\n",
    "mx = mini[['age', 'tenure_months', 'monthly_charges', 'support_calls']].to_numpy()  # extract numeric matrix\n",
    "mx_std = (mx - mx.mean(axis=0)) / mx.std(axis=0)  # standardize features to mean 0, std 1\n",
    "w = np.array([0.2, -0.3, 0.15, 0.25])  # arbitrary weights for illustration (not trained)\n",
    "b = -0.1  # arbitrary intercept (bias term)\n",
    "z_manual = mx_std @ w + b  # linear score z = Xw + b\n",
    "p_manual = 1 / (1 + np.exp(-z_manual))  # sigmoid to convert z to probability p\n",
    "\n",
    "# Compute binary cross-entropy log loss for the mini-batch\n",
    "y_true = mini['churn'].to_numpy()  # true labels for the mini-batch\n",
    "eps = 1e-9  # epsilon to avoid log(0)\n",
    "log_loss = -np.mean(y_true * np.log(p_manual + eps) + (1 - y_true) * np.log(1 - p_manual + eps))  # average log loss\n",
    "\n",
    "# Show results\n",
    "print('z (manual):', np.round(z_manual, 3))  # show linear scores\n",
    "print('p (manual sigmoid):', np.round(p_manual, 3))  # show probabilities\n",
    "print('y (true):', y_true)  # show true labels\n",
    "print(f'Log Loss (manual): {log_loss:.4f}')  # show computed log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba9d0a5",
   "metadata": {},
   "source": [
    "## Probability Calibration Comparison\n",
    "We compare calibration of Logistic Regression vs Random Forest on the same test set.\n",
    "(See glossary: Probability Calibration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a907bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a RandomForestClassifier for comparison\n",
    "rf = Pipeline([  # build a pipeline mirroring preprocessing\n",
    "    ('prep', preprocess),  # reuse the same preprocessing steps\n",
    "    ('rf', RandomForestClassifier(n_estimators=300, random_state=42))  # random forest model\n",
    "])\n",
    "rf.fit(X_train, y_train)  # train RF on training data\n",
    "rf_proba = rf.predict_proba(X_test)[:, 1]  # probability of class 1 from RF\n",
    "\n",
    "# Compute calibration curves (fraction of positives vs mean predicted value)\n",
    "lr_frac_pos, lr_mean_pred = calibration_curve(y_test, y_proba, n_bins=10, strategy='uniform')  # LR calibration\n",
    "rf_frac_pos, rf_mean_pred = calibration_curve(y_test, rf_proba, n_bins=10, strategy='uniform')  # RF calibration\n",
    "\n",
    "# Plot calibration curves\n",
    "plt.figure(figsize=(6, 5))  # set figure size\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Perfectly Calibrated')  # ideal diagonal\n",
    "plt.plot(lr_mean_pred, lr_frac_pos, marker='o', label='Logistic Regression')  # LR curve\n",
    "plt.plot(rf_mean_pred, rf_frac_pos, marker='s', label='Random Forest')  # RF curve\n",
    "plt.xlabel('Mean Predicted Probability')  # x-label\n",
    "plt.ylabel('Fraction of Positives')  # y-label\n",
    "plt.title('Calibration Curves')  # title\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fe59f5",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "Complete these tasks; then check your work in the Solutions section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530a0f7",
   "metadata": {},
   "source": [
    "1) Threshold Tuning (see glossary: Threshold)\n",
    "- Compute precision, recall, and F1 for thresholds in [0.2, 0.3, ..., 0.8].\n",
    "- Plot threshold vs each metric.\n",
    "- Choose an operating point for a retention budget that tolerates some false positives.\n",
    "\n",
    "2) Feature Impact (see glossary: Odds Ratio)\n",
    "- Extract coefficients from the trained Logistic Regression.\n",
    "- Convert coefficients to odds ratios (exp(coef)).\n",
    "- Interpret two of the strongest effects in plain language.\n",
    "\n",
    "3) Calibration Check (see glossary: Probability Calibration)\n",
    "- Compute the Brier score for Logistic Regression and Random Forest.\n",
    "- Which model is better calibrated on this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8f3235",
   "metadata": {},
   "source": [
    "## Solutions (Expand to Reveal)\n",
    "\n",
    "<details>\n",
    "<summary><strong>Solution 1: Threshold Tuning</strong></summary>\n",
    "\n",
    "```python\n",
    "# Evaluate metrics across thresholds (0.2 to 0.8)\n",
    "thresholds = np.arange(0.2, 0.81, 0.1)  # define thresholds to test\n",
    "precisions_list, recalls_list, f1_list = [], [], []  # holders for metrics\n",
    "for t in thresholds:  # iterate over thresholds\n",
    "    y_pred_t = (y_proba >= t).astype(int)  # apply threshold t\n",
    "    precisions_list.append(precision_score(y_test, y_pred_t))  # store precision\n",
    "    recalls_list.append(recall_score(y_test, y_pred_t))  # store recall\n",
    "    f1_list.append(f1_score(y_test, y_pred_t))  # store f1\n",
    "plt.figure(figsize=(7, 4))  # figure size\n",
    "plt.plot(thresholds, precisions_list, label='Precision')  # precision curve\n",
    "plt.plot(thresholds, recalls_list, label='Recall')  # recall curve\n",
    "plt.plot(thresholds, f1_list, label='F1')  # f1 curve\n",
    "plt.xlabel('Threshold')  # label x-axis\n",
    "plt.ylabel('Metric')  # label y-axis\n",
    "plt.title('Metrics vs Threshold')  # title\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Solution 2: Feature Impact (Odds Ratios)</strong></summary>\n",
    "\n",
    "```python\n",
    "# Extract LR step from pipeline and compute odds ratios\n",
    "lr_step = clf.named_steps['lr']  # get logistic regression object\n",
    "# Build feature names after preprocessing (numeric + one-hot categories)\n",
    "ohe = clf.named_steps['prep'].named_transformers_['cat'].named_steps['encoder']  # OHE transformer\n",
    "num_feature_names = num_cols  # numeric names unchanged\n",
    "cat_feature_names = list(ohe.get_feature_names_out(cat_cols))  # expanded categorical names\n",
    "feature_names = num_feature_names + cat_feature_names  # full list in order\n",
    "coefficients = lr_step.coef_.ravel()  # 1D array of coefficients\n",
    "odds_ratios = np.exp(coefficients)  # convert to odds ratios\n",
    "impact = pd.DataFrame({'feature': feature_names, 'coef': coefficients, 'odds_ratio': odds_ratios})  # table\n",
    "impact.sort_values('odds_ratio', ascending=False).head(10)  # view top effects\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Solution 3: Calibration (Brier Score)</strong></summary>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import brier_score_loss  # import Brier score function\n",
    "lr_brier = brier_score_loss(y_test, y_proba)  # LR Brier score\n",
    "rf_brier = brier_score_loss(y_test, rf_proba)  # RF Brier score\n",
    "print('Brier (LR):', round(lr_brier, 4))  # show LR score\n",
    "print('Brier (RF):', round(rf_brier, 4))  # show RF score\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43ee99c",
   "metadata": {},
   "source": [
    "## Environment and Versions\n",
    "Record library versions for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77586cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show library versions for run-to-run reproducibility\n",
    "import sklearn  # import scikit-learn to report version\n",
    "print(f'scikit-learn: {sklearn.__version__}')  # print scikit-learn version\n",
    "import sys  # Python runtime information\n",
    "print(f'Python: {sys.version.split()[0]}')  # print Python version number only"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
