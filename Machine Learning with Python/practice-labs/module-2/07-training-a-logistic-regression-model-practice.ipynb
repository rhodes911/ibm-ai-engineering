{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab144e4a",
   "metadata": {},
   "source": [
    "# Training a Logistic Regression Model: GD, SGD, and Solvers\n",
    "\n",
    ".\n",
    "## Overview\n",
    "In this practice lab you will:\n",
    "- Implement logistic regression training via Batch GD, Mini-batch GD, and SGD\n",
    "- Explore learning rates, schedules, and early stopping\n",
    "- Compare manual training with scikit-learn solvers (`lbfgs`, `liblinear`, `saga`)\n",
    "- Analyze log loss curves and generalization with a validation split\n",
    "- Practice threshold selection and interpretability of coefficients\n",
    ".\n",
    "## Key Concepts and Glossary References\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - Logistic Regression\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - Log Loss (Binary Cross-Entropy)\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - Gradient Descent\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - Batch Gradient Descent / Mini-batch / SGD\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - Learning Rate / Schedule / Early Stopping\n",
    "- See: `Machine Learning with Python/notes/glossary-module-2.md` - `solver`, `penalty`, `C`, `class_weight`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccbc3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Me First: setup and packages\n",
    "import numpy as np  # numerical computing\n",
    "import pandas as pd  # data manipulation\n",
    "import seaborn as sns  # visualization\n",
    "import matplotlib.pyplot as plt  # plotting backend\n",
    "from sklearn.model_selection import train_test_split  # data splitting\n",
    "from sklearn.preprocessing import StandardScaler  # feature scaling\n",
    "from sklearn.pipeline import Pipeline  # compose preprocessing + model\n",
    "from sklearn.linear_model import LogisticRegression  # logistic model\n",
    "from sklearn.metrics import log_loss, accuracy_score, precision_recall_fscore_support, roc_auc_score  # metrics\n",
    "\n",
    "# reproducibility\n",
    "np.random.seed(42)  # set global NumPy seed\n",
    "PY_RANDOM_SEED = 42  # explicit constant to reuse in comments\n",
    "\n",
    "# plotting defaults for consistent look\n",
    "sns.set(style=\"whitegrid\", context=\"notebook\")  # seaborn theme\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)  # default figure size\n",
    "plt.rcParams[\"axes.titlesize\"] = 14  # title size\n",
    "plt.rcParams[\"axes.labelsize\"] = 12  # axis label size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2bd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic dataset: realistic e-commerce conversion scenario\n",
    "# We simulate a binary outcome: whether a visitor converts (1) or not (0)\n",
    "# Features: sessions, pages_per_session, is_mobile, is_campaign, time_on_site, country_US\n",
    "n = 800  # number of samples\n",
    "rng = np.random.default_rng(PY_RANDOM_SEED)  # random generator\n",
    "\n",
    "# base features with reasonable distributions\n",
    "sessions = rng.poisson(lam=3.5, size=n)  # visits per week\n",
    "pages_per_session = rng.normal(loc=5.0, scale=1.2, size=n).clip(1, None)  # pages per visit\n",
    "is_mobile = rng.binomial(1, 0.6, size=n)  # 60% mobile traffic\n",
    "is_campaign = rng.binomial(1, 0.3, size=n)  # 30% currently in a campaign cohort\n",
    "time_on_site = rng.gamma(shape=2.0, scale=90.0, size=n)  # seconds on site\n",
    "country_US = rng.binomial(1, 0.65, size=n)  # 65% from US\n",
    "\n",
    "# combine into design matrix (without intercept yet)\n",
    "X = np.column_stack([sessions, pages_per_session, is_mobile, is_campaign, time_on_site, country_US])  # features matrix\n",
    "feature_names = [\"sessions\", \"pages_per_session\", \"is_mobile\", \"is_campaign\", \"time_on_site\", \"country_US\"]  # names\n",
    "\n",
    "# true underlying weights for logistic model (ground truth for simulation)\n",
    "w_true = np.array([0.25, 0.35, -0.4, 0.9, 0.002, 0.15])  # coefficients\n",
    "b_true = -2.0  # intercept term (bias)\n",
    "\n",
    "# sigmoid helper\n",
    "sigmoid = lambda z: 1.0 / (1.0 + np.exp(-z))  # maps real line to (0,1)\n",
    "\n",
    "# generate probabilities then sample binary labels\n",
    "logits = X @ w_true + b_true  # linear combination\n",
    "proba = sigmoid(logits)  # convert to probabilities\n",
    "# add a few outliers by flipping some labels to simulate noise\n",
    "y = rng.binomial(1, proba)  # sample labels from Bernoulli\n",
    "flip_idx = rng.choice(n, size=20, replace=False)  # choose indices to flip\n",
    "y[flip_idx] = 1 - y[flip_idx]  # flip labels to add noise\n",
    "\n",
    "# build DataFrame for EDA\n",
    "raw_df = pd.DataFrame(X, columns=feature_names)  # create DataFrame\n",
    "raw_df[\"converted\"] = y  # add target column\n",
    "\n",
    "# quick peek\n",
    "raw_df.head()  # show first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d851f",
   "metadata": {},
   "source": [
    "# Data dictionary (markdown)\n",
    "\n",
    "#\n",
    "\n",
    "| Column            | Type   | Description                                         |\n",
    "\n",
    "|-------------------|--------|-----------------------------------------------------|\n",
    "\n",
    "| sessions          | int    | Visits per week for the user                        |\n",
    "\n",
    "| pages_per_session | float  | Average pages viewed per visit                      |\n",
    "\n",
    "| is_mobile         | int    | 1 if mobile device, else 0                          |\n",
    "\n",
    "| is_campaign       | int    | 1 if user part of current marketing campaign         |\n",
    "\n",
    "| time_on_site      | float  | Total time on site this week (seconds)              |\n",
    "\n",
    "| country_US        | int    | 1 if user is in the US, else 0                      |\n",
    "\n",
    "| converted         | int    | Target: 1 if user converted, else 0                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a97f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation/test split for honest evaluation\n",
    "from sklearn.model_selection import StratifiedShuffleSplit  # stratified splitting\n",
    "\n",
    "# create stratified splits to preserve class balance\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=PY_RANDOM_SEED)  # 80/20 split\n",
    "idx_train_val, idx_test = next(sss.split(raw_df[feature_names], raw_df[\"converted\"]))  # indices\n",
    "\n",
    "df_train_val = raw_df.iloc[idx_train_val].reset_index(drop=True)  # training+validation\n",
    "df_test = raw_df.iloc[idx_test].reset_index(drop=True)  # hold-out test set\n",
    "\n",
    "# now split train into train/val\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.25, random_state=PY_RANDOM_SEED)  # 75/25 of 80% -> 60/20/20 overall\n",
    "idx_train, idx_val = next(sss2.split(df_train_val[feature_names], df_train_val[\"converted\"]))  # indices\n",
    "\n",
    "df_train = df_train_val.iloc[idx_train].reset_index(drop=True)  # 60%\n",
    "df_val = df_train_val.iloc[idx_val].reset_index(drop=True)  # 20%\n",
    "\n",
    "# extract arrays for modeling\n",
    "X_train = df_train[feature_names].to_numpy()  # features train\n",
    "y_train = df_train[\"converted\"].to_numpy()  # labels train\n",
    "X_val = df_val[feature_names].to_numpy()  # features val\n",
    "y_val = df_val[\"converted\"].to_numpy()  # labels val\n",
    "X_test = df_test[feature_names].to_numpy()  # features test\n",
    "y_test = df_test[\"converted\"].to_numpy()  # labels test\n",
    "\n",
    "# quick class balance check\n",
    "print(\"Class balance (train/val/test):\",  # print label means\n",
    "      y_train.mean().round(3), y_val.mean().round(3), y_test.mean().round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87d183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: quick distributions and correlations\n",
    "ax = sns.histplot(df_train[\"pages_per_session\"], kde=True)  # histogram with KDE\n",
    "ax.set_title(\"Pages per session (train)\")  # title\n",
    "plt.show()  # render plot\n",
    "\n",
    "ax = sns.scatterplot(x=\"time_on_site\", y=\"pages_per_session\", hue=\"converted\", data=df_train, alpha=0.6)  # scatter\n",
    "ax.set_title(\"Time on site vs Pages/session (colored by conversion)\")  # title\n",
    "plt.show()  # render plot\n",
    "\n",
    "corr = df_train[feature_names + [\"converted\"]].corr(numeric_only=True)  # compute correlation matrix\n",
    "sns.heatmap(corr, annot=False, cmap=\"coolwarm\", center=0)  # heatmap\n",
    "plt.title(\"Correlation heatmap (train)\")  # title\n",
    "plt.show()  # render plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b9a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual logistic regression with Batch GD, Mini-batch, and SGD\n",
    "# Helper functions for sigmoid, log loss, and gradient\n",
    "import math  # math utilities\n",
    "\n",
    "def sigmoid_np(z: np.ndarray) -> np.ndarray:  # vectorized sigmoid\n",
    "    return 1.0 / (1.0 + np.exp(-z))  # elementwise sigmoid\n",
    "\n",
    "def add_intercept(Xm: np.ndarray) -> np.ndarray:  # add bias column of ones\n",
    "    return np.c_[np.ones((Xm.shape[0], 1)), Xm]  # prepend ones column\n",
    "\n",
    "def binary_log_loss(y_true: np.ndarray, y_prob: np.ndarray, eps: float = 1e-15) -> float:  # compute average log loss\n",
    "    y_prob = np.clip(y_prob, eps, 1 - eps)  # avoid log(0)\n",
    "    return float(-(y_true * np.log(y_prob) + (1 - y_true) * np.log(1 - y_prob)).mean())  # scalar loss\n",
    "\n",
    "# Standardize features (important for gradient-based methods)\n",
    "scaler = StandardScaler()  # create scaler\n",
    "X_train_s = scaler.fit_transform(X_train)  # fit+transform train\n",
    "X_val_s = scaler.transform(X_val)  # transform val\n",
    "X_test_s = scaler.transform(X_test)  # transform test\n",
    "\n",
    "# Add intercept\n",
    "Xtr = add_intercept(X_train_s)  # train with intercept\n",
    "Xv = add_intercept(X_val_s)  # val with intercept\n",
    "Xte = add_intercept(X_test_s)  # test with intercept\n",
    "\n",
    "# Initialize weights\n",
    "n_features = Xtr.shape[1]  # number of columns incl. intercept\n",
    "w0 = np.zeros(n_features)  # start from zeros\n",
    "\n",
    "# Training loop factory\n",
    "from typing import Tuple, List  # typing annotations\n",
    "\n",
    "def train_logreg(\n",
    "    X: np.ndarray, y: np.ndarray, X_val_: np.ndarray, y_val_: np.ndarray,\n",
    "    w_init: np.ndarray, lr: float = 0.1, epochs: int = 200,\n",
    "    batch_size: int | None = None, shuffle: bool = True,\n",
    "    early_stopping: bool = True, patience: int = 10,\n",
    ") -> Tuple[np.ndarray, List[float], List[float]]:\n",
    "    \"\"\"Train logistic regression with GD/SGD/mini-batch.\n",
    "    - If batch_size is None or equals n, performs Batch GD.\n",
    "    - If batch_size == 1, performs SGD.\n",
    "    - Otherwise, performs Mini-batch GD.\n",
    "    Returns: (weights, train_losses, val_losses)\n",
    "    \"\"\"\n",
    "    rng_local = np.random.default_rng(PY_RANDOM_SEED)  # local RNG\n",
    "    n = X.shape[0]  # number of samples\n",
    "    bs = n if (batch_size is None) else batch_size  # effective batch size\n",
    "    w = w_init.copy()  # copy initial weights\n",
    "    best_val = math.inf  # best validation loss\n",
    "    best_w = w.copy()  # best weights snapshot\n",
    "    wait = 0  # patience counter\n",
    "    train_losses, val_losses = [], []  # history\n",
    "\n",
    "    for epoch in range(epochs):  # iterate over epochs\n",
    "        indices = np.arange(n)  # indices 0..n-1\n",
    "        if shuffle:  # shuffle each epoch\n",
    "            rng_local.shuffle(indices)  # in-place shuffle\n",
    "        # iterate over batches\n",
    "        for start in range(0, n, bs):  # batch loop\n",
    "            idx = indices[start:start + bs]  # batch indices\n",
    "            Xb = X[idx]  # batch features\n",
    "            yb = y[idx]  # batch labels\n",
    "            # predictions and gradient\n",
    "            p = sigmoid_np(Xb @ w)  # probs\n",
    "            grad = Xb.T @ (p - yb) / Xb.shape[0]  # gradient of log loss\n",
    "            w -= lr * grad  # gradient descent step\n",
    "        # end of epoch: evaluate\n",
    "        p_tr = sigmoid_np(X @ w)  # train probabilities\n",
    "        p_va = sigmoid_np(X_val_ @ w)  # val probabilities\n",
    "        tr_loss = binary_log_loss(y, p_tr)  # train loss\n",
    "        va_loss = binary_log_loss(y_val_, p_va)  # val loss\n",
    "        train_losses.append(tr_loss)  # log train loss\n",
    "        val_losses.append(va_loss)  # log val loss\n",
    "        # early stopping\n",
    "        if early_stopping:\n",
    "            if va_loss + 1e-8 < best_val:  # improvement check\n",
    "                best_val = va_loss  # update best\n",
    "                best_w = w.copy()  # snapshot\n",
    "                wait = 0  # reset patience\n",
    "            else:\n",
    "                wait += 1  # increment patience\n",
    "                if wait >= patience:  # stop if patience exceeded\n",
    "                    w = best_w  # restore best weights\n",
    "                    break  # exit training loop\n",
    "    return w, train_losses, val_losses  # return results\n",
    "\n",
    "# Run three modes: Batch GD, Mini-batch, and SGD\n",
    "w_gd, tr_gd, va_gd = train_logreg(Xtr, y_train, Xv, y_val, w0, lr=0.2, epochs=300, batch_size=None, patience=15)  # Batch GD\n",
    "w_mb, tr_mb, va_mb = train_logreg(Xtr, y_train, Xv, y_val, w0, lr=0.2, epochs=300, batch_size=64, patience=15)  # Mini-batch 64\n",
    "w_sgd, tr_sgd, va_sgd = train_logreg(Xtr, y_train, Xv, y_val, w0, lr=0.05, epochs=300, batch_size=1, patience=20)  # pure SGD\n",
    "\n",
    "# Plot validation loss curves to compare\n",
    "plt.plot(va_gd, label=\"Batch GD\")  # plot GD\n",
    "plt.plot(va_mb, label=\"Mini-batch (64)\")  # plot MB\n",
    "plt.plot(va_sgd, label=\"SGD\")  # plot SGD\n",
    "plt.xlabel(\"Epoch\")  # x label\n",
    "plt.ylabel(\"Validation Log Loss\")  # y label\n",
    "plt.title(\"Validation loss by training method\")  # title\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e720c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate manual model on test set (best of three by val loss)\n",
    "# pick the best validation performer\n",
    "val_losses = {\"gd\": va_gd[-1], \"mb\": va_mb[-1], \"sgd\": va_sgd[-1]}  # last-epoch val losses\n",
    "best_key = min(val_losses, key=val_losses.get)  # argmin\n",
    "w_best = {\"gd\": w_gd, \"mb\": w_mb, \"sgd\": w_sgd}[best_key]  # select weights\n",
    "\n",
    "# test metrics\n",
    "p_test = sigmoid_np(Xte @ w_best)  # test probabilities\n",
    "pred_test = (p_test >= 0.5).astype(int)  # 0.5 threshold\n",
    "acc = accuracy_score(y_test, pred_test)  # accuracy\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, pred_test, average=\"binary\")  # PRF1\n",
    "auc = roc_auc_score(y_test, p_test)  # ROC-AUC\n",
    "ll = binary_log_loss(y_test, p_test)  # log loss\n",
    "print({\"best\": best_key, \"accuracy\": round(acc, 3), \"precision\": round(prec, 3), \"recall\": round(rec, 3), \"f1\": round(f1, 3), \"roc_auc\": round(auc, 3), \"log_loss\": round(ll, 3)})  # results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c8eb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with scikit-learn solvers and pipelines\n",
    "solvers = [\"lbfgs\", \"liblinear\", \"saga\"]  # chosen solvers\n",
    "results = []  # collect metrics\n",
    "for solver in solvers:  # iterate options\n",
    "    pipe = Pipeline([  # build pipeline\n",
    "        (\"scaler\", StandardScaler()),  # scale features\n",
    "        (\"lr\", LogisticRegression(solver=solver, penalty=\"l2\", C=1.0, max_iter=2000, random_state=PY_RANDOM_SEED))  # model\n",
    "    ])\n",
    "    pipe.fit(df_train[feature_names], y_train)  # fit on train\n",
    "    p_val = pipe.predict_proba(df_val[feature_names])[:, 1]  # val probabilities\n",
    "    p_test = pipe.predict_proba(df_test[feature_names])[:, 1]  # test probabilities\n",
    "    y_pred = (p_test >= 0.5).astype(int)  # threshold at 0.5\n",
    "    res = {  # metrics dict\n",
    "        \"solver\": solver,\n",
    "        \"val_log_loss\": round(log_loss(y_val, p_val), 3),  # validation log loss\n",
    "        \"test_log_loss\": round(log_loss(y_test, p_test), 3),  # test log loss\n",
    "        \"test_accuracy\": round(accuracy_score(y_test, y_pred), 3),  # accuracy\n",
    "        \"roc_auc\": round(roc_auc_score(y_test, p_test), 3),  # AUC\n",
    "    }\n",
    "    results.append(res)  # store\n",
    "results  # show comparison table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate schedule demo (time-based decay)\n",
    "# η_t = η0 / (1 + decay * t)\n",
    "\n",
    "def time_decay_lr(eta0: float, decay: float, t: int) -> float:  # schedule function\n",
    "    return eta0 / (1.0 + decay * t)  # decayed LR\n",
    "\n",
    "# train with schedule by updating lr each epoch\n",
    "w_sched = w0.copy()  # init\n",
    "eta0, decay = 0.3, 0.02  # initial lr and decay\n",
    "train_hist, val_hist = [], []  # histories\n",
    "for t in range(200):  # epochs\n",
    "    # single batch GD for simplicity\n",
    "    p = sigmoid_np(Xtr @ w_sched)  # probs\n",
    "    grad = Xtr.T @ (p - y_train) / Xtr.shape[0]  # gradient\n",
    "    lr_t = time_decay_lr(eta0, decay, t)  # lr at t\n",
    "    w_sched -= lr_t * grad  # step\n",
    "    # record losses\n",
    "    train_hist.append(binary_log_loss(y_train, sigmoid_np(Xtr @ w_sched)))  # train loss\n",
    "    val_hist.append(binary_log_loss(y_val, sigmoid_np(Xv @ w_sched)))  # val loss\n",
    "\n",
    "# plot schedule curve\n",
    "plt.plot(val_hist, label=\"Time decay schedule\")  # plot\n",
    "plt.xlabel(\"Epoch\")  # x label\n",
    "plt.ylabel(\"Validation Log Loss\")  # y label\n",
    "plt.title(\"Learning rate schedule: time-based decay\")  # title\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8777e5a",
   "metadata": {},
   "source": [
    "# Practice Exercises\n",
    "\n",
    "1) Try three different learning rates for Batch GD (e.g., 0.01, 0.1, 0.5). Plot validation loss and explain which converges best and why.\n",
    "\n",
    "2) Implement early stopping with patience=5 for Mini-batch GD and show the selected epoch. Compare to training without early stopping.\n",
    "\n",
    "3) Compare solvers with `penalty='l1'` (where supported) and discuss sparsity of coefficients.\n",
    "\n",
    "4) Tune threshold to maximize F1 on the validation set, then report test metrics at that threshold.\n",
    "\n",
    "5) Optional: Add `class_weight='balanced'` and compare ROC-AUC on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Try three learning rates for Batch GD\n",
    "learning_rates = [0.01, 0.1, 0.5]  # candidate LRs\n",
    "curves = {}  # store validation losses\n",
    "for lr in learning_rates:  # iterate LRs\n",
    "    w_tmp, _, vloss = train_logreg(Xtr, y_train, Xv, y_val, w0, lr=lr, epochs=200, batch_size=None, patience=15)  # train\n",
    "    curves[lr] = vloss  # save curve\n",
    "# plot curves\n",
    "for lr, vloss in curves.items():  # iterate results\n",
    "    plt.plot(vloss, label=f\"lr={lr}\")  # plot one curve\n",
    "plt.title(\"Validation loss for different learning rates (Batch GD)\")  # title\n",
    "plt.xlabel(\"Epoch\")  # x label\n",
    "plt.ylabel(\"Val Log Loss\")  # y label\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53475384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2: Early stopping for Mini-batch GD (patience=5)\n",
    "w_es, tr_es, va_es = train_logreg(Xtr, y_train, Xv, y_val, w0, lr=0.2, epochs=300, batch_size=64, patience=5)  # train with ES\n",
    "plt.plot(va_es, label=\"Mini-batch with early stopping\")  # plot\n",
    "plt.xlabel(\"Epoch\")  # x label\n",
    "plt.ylabel(\"Val Log Loss\")  # y label\n",
    "plt.legend()  # legend\n",
    "plt.show()  # render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b88b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3: L1 penalty (where supported) and sparsity\n",
    "res_l1 = []  # store\n",
    "for solver in [\"liblinear\", \"saga\"]:  # solvers supporting L1\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),  # scale\n",
    "        (\"lr\", LogisticRegression(solver=solver, penalty=\"l1\", C=0.5, max_iter=2000, random_state=PY_RANDOM_SEED))  # L1\n",
    "    ])\n",
    "    pipe.fit(df_train[feature_names], y_train)  # fit\n",
    "    coef = pipe.named_steps[\"lr\"].coef_.ravel()  # coefficients\n",
    "    sparsity = float((coef == 0).mean())  # fraction zero\n",
    "    res_l1.append({\"solver\": solver, \"sparsity\": round(sparsity, 3), \"coef\": coef})  # record\n",
    "res_l1  # inspect sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6dc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4: Threshold tuning for F1 on validation set\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"lr\", LogisticRegression(solver=\"lbfgs\", C=1.0, max_iter=2000, random_state=PY_RANDOM_SEED))])  # pipeline\n",
    "pipe.fit(df_train[feature_names], y_train)  # fit on train\n",
    "p_val = pipe.predict_proba(df_val[feature_names])[:, 1]  # val probs\n",
    "best_f1, best_t = -1.0, 0.5  # init\n",
    "for t in np.linspace(0.1, 0.9, 33):  # candidate thresholds\n",
    "    y_hat = (p_val >= t).astype(int)  # predictions\n",
    "    _, _, f1, _ = precision_recall_fscore_support(y_val, y_hat, average=\"binary\")  # F1\n",
    "    if f1 > best_f1:  # update best\n",
    "        best_f1, best_t = float(f1), float(t)  # store\n",
    "# evaluate on test at best threshold\n",
    "p_test = pipe.predict_proba(df_test[feature_names])[:, 1]  # test probs\n",
    "y_hat_test = (p_test >= best_t).astype(int)  # apply threshold\n",
    "acc = accuracy_score(y_test, y_hat_test)  # accuracy\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_hat_test, average=\"binary\")  # PRF1\n",
    "print({\"best_threshold\": round(best_t, 3), \"test_accuracy\": round(acc, 3), \"precision\": round(prec, 3), \"recall\": round(rec, 3), \"f1\": round(f1, 3)})  # report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27887165",
   "metadata": {},
   "source": [
    "# Solutions (expand if desired)\n",
    "This section provides reference implementations matching the exercises above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f19e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version info for reproducibility\n",
    "import sys  # python runtime\n",
    "import sklearn  # scikit-learn\n",
    "import seaborn  # seaborn version\n",
    "print({\"python\": sys.version.split()[0], \"numpy\": np.__version__, \"pandas\": pd.__version__, \"sklearn\": sklearn.__version__, \"seaborn\": seaborn.__version__})  # versions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
