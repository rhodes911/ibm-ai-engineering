{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f72c9f",
   "metadata": {},
   "source": [
    "# Practice Lab: Multiple Linear Regression\n",
    "\n",
    "**Module 2 - Lesson 3**  \n",
    "**Date:** November 11, 2025\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "In this practice lab, you will:\n",
    "- ‚úÖ Build multiple linear regression models with 2+ features\n",
    "- ‚úÖ Understand matrix representation (X, Œ∏)\n",
    "- ‚úÖ Handle categorical variables (one-hot encoding)\n",
    "- ‚úÖ Detect and address multicollinearity\n",
    "- ‚úÖ Perform what-if scenario analysis\n",
    "- ‚úÖ Compare OLS vs Gradient Descent\n",
    "- ‚úÖ Visualize hyperplanes (3D regression planes)\n",
    "- ‚úÖ Interpret coefficients and feature importance\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Real-World Scenario: Real Estate Valuation\n",
    "\n",
    "You're a data scientist at **Metro Realty**, a real estate company. Your goal is to build an accurate house price prediction model considering multiple factors:\n",
    "\n",
    "**Why Multiple Features?**\n",
    "- House price depends on size, location, age, amenities, etc.\n",
    "- Using only one feature (e.g., square footage) ignores other important factors\n",
    "- Multiple regression captures the combined effect of all features\n",
    "\n",
    "**Dataset Features:**\n",
    "- `house_id`: Unique identifier\n",
    "- `sqft`: Square footage\n",
    "- `bedrooms`: Number of bedrooms\n",
    "- `bathrooms`: Number of bathrooms\n",
    "- `age_years`: Age of house in years\n",
    "- `garage_spaces`: Garage capacity\n",
    "- `location`: Neighborhood (categorical: Urban/Suburban/Rural)\n",
    "- `has_pool`: Pool present (categorical: Yes/No)\n",
    "- `condition`: House condition score (1-10)\n",
    "- `price_usd`: **TARGET** - House price in USD\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70353f4",
   "metadata": {},
   "source": [
    "## üîß Setup: Run Me First!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3e8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 2)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(f\"NumPy: {np.__version__} | Pandas: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d0a0c7",
   "metadata": {},
   "source": [
    "## üì¶ Generate Synthetic Real Estate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 200 house records\n",
    "n_samples = 200\n",
    "\n",
    "# Generate continuous features\n",
    "sqft = np.random.uniform(1000, 4000, n_samples).round(0)\n",
    "bedrooms = np.random.choice([2, 3, 4, 5, 6], n_samples)\n",
    "bathrooms = np.random.choice([1, 1.5, 2, 2.5, 3, 3.5], n_samples)\n",
    "age_years = np.random.uniform(0, 50, n_samples).round(0)\n",
    "garage_spaces = np.random.choice([0, 1, 2, 3], n_samples, p=[0.1, 0.3, 0.4, 0.2])\n",
    "condition = np.random.uniform(4, 10, n_samples).round(1)\n",
    "\n",
    "# Generate categorical features\n",
    "location = np.random.choice(['Urban', 'Suburban', 'Rural'], n_samples, p=[0.4, 0.4, 0.2])\n",
    "has_pool = np.random.choice(['Yes', 'No'], n_samples, p=[0.3, 0.7])\n",
    "\n",
    "# Generate price based on realistic formula with correlations\n",
    "base_price = (\n",
    "    50000 +                                    # Base cost\n",
    "    sqft * 150 +                              # $150 per sqft\n",
    "    bedrooms * 20000 +                        # $20k per bedroom\n",
    "    bathrooms * 15000 +                       # $15k per bathroom\n",
    "    -age_years * 2000 +                       # Depreciation $2k/year\n",
    "    garage_spaces * 10000 +                   # $10k per garage space\n",
    "    condition * 5000 +                        # $5k per condition point\n",
    "    (location == 'Urban') * 80000 +           # Urban premium $80k\n",
    "    (location == 'Suburban') * 40000 +        # Suburban premium $40k\n",
    "    (has_pool == 'Yes') * 25000               # Pool adds $25k\n",
    ")\n",
    "\n",
    "# Add realistic noise (¬±12%)\n",
    "noise = np.random.normal(0, base_price * 0.12, n_samples)\n",
    "price_usd = (base_price + noise).round(2)\n",
    "\n",
    "# Ensure minimum price\n",
    "price_usd = np.maximum(price_usd, 150000)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'house_id': [f'H{i:04d}' for i in range(1, n_samples + 1)],\n",
    "    'sqft': sqft,\n",
    "    'bedrooms': bedrooms,\n",
    "    'bathrooms': bathrooms,\n",
    "    'age_years': age_years,\n",
    "    'garage_spaces': garage_spaces,\n",
    "    'location': location,\n",
    "    'has_pool': has_pool,\n",
    "    'condition': condition,\n",
    "    'price_usd': price_usd\n",
    "})\n",
    "\n",
    "print(\"‚úÖ Real estate dataset generated!\")\n",
    "print(f\"\\nüìä Dataset: {df.shape[0]} houses, {df.shape[1]} columns\")\n",
    "print(f\"\\nüí∞ Price range: ${df['price_usd'].min():,.0f} - ${df['price_usd'].max():,.0f}\")\n",
    "print(f\"   Average price: ${df['price_usd'].mean():,.0f}\")\n",
    "print(\"\\nüè† Sample houses:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90502c6",
   "metadata": {},
   "source": [
    "## üìä Data Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8bfc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìö Data Dictionary\\n\")\n",
    "print(\"Continuous Features:\")\n",
    "print(\"  sqft           - House size in square feet (1,000-4,000)\")\n",
    "print(\"  bedrooms       - Number of bedrooms (2-6)\")\n",
    "print(\"  bathrooms      - Number of bathrooms (1-3.5)\")\n",
    "print(\"  age_years      - Age of house (0-50 years)\")\n",
    "print(\"  garage_spaces  - Garage capacity (0-3 cars)\")\n",
    "print(\"  condition      - House condition score (4-10)\")\n",
    "print(\"\\nCategorical Features:\")\n",
    "print(\"  location       - Neighborhood type (Urban/Suburban/Rural)\")\n",
    "print(\"  has_pool       - Swimming pool present (Yes/No)\")\n",
    "print(\"\\nTarget Variable:\")\n",
    "print(\"  price_usd      - üéØ House sale price in USD\")\n",
    "\n",
    "# Dataset info\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087dcd7d",
   "metadata": {},
   "source": [
    "## üìà Concept 1: Handling Categorical Variables\n",
    "\n",
    "**Problem:** Regression models require numerical inputs, but we have categorical features (location, has_pool).\n",
    "\n",
    "**Solutions:**\n",
    "1. **Binary encoding** for 2 categories (0/1)\n",
    "2. **One-hot encoding** for 3+ categories (create binary columns)\n",
    "3. **Dummy variable trap:** Drop one category to avoid perfect multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eca843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before encoding\n",
    "print(\"üîç BEFORE Encoding:\")\n",
    "print(df[['house_id', 'location', 'has_pool', 'price_usd']].head(10))\n",
    "\n",
    "# Create copy for encoding\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Binary encoding: has_pool (Yes=1, No=0)\n",
    "df_encoded['has_pool_binary'] = (df_encoded['has_pool'] == 'Yes').astype(int)\n",
    "\n",
    "# One-hot encoding: location (3 categories ‚Üí 2 dummy variables)\n",
    "location_dummies = pd.get_dummies(df_encoded['location'], prefix='location', drop_first=True)\n",
    "df_encoded = pd.concat([df_encoded, location_dummies], axis=1)\n",
    "\n",
    "print(\"\\n\\n‚úÖ AFTER Encoding:\")\n",
    "print(df_encoded[['house_id', 'has_pool_binary', 'location_Suburban', 'location_Urban', 'price_usd']].head(10))\n",
    "\n",
    "print(\"\\n\\nüìä Encoding Explanation:\")\n",
    "print(\"  has_pool: Yes ‚Üí 1, No ‚Üí 0\")\n",
    "print(\"  \\n  location (dropped 'Rural' to avoid dummy trap):\")\n",
    "print(\"    Rural     ‚Üí location_Suburban=0, location_Urban=0\")\n",
    "print(\"    Suburban  ‚Üí location_Suburban=1, location_Urban=0\")\n",
    "print(\"    Urban     ‚Üí location_Suburban=0, location_Urban=1\")\n",
    "\n",
    "# Verify encoding\n",
    "print(\"\\n\\nüîç Verification:\")\n",
    "verification = df_encoded.groupby('location')[['location_Suburban', 'location_Urban']].mean()\n",
    "print(verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1e1570",
   "metadata": {},
   "source": [
    "## üìä Concept 2: Detecting Multicollinearity\n",
    "\n",
    "**Multicollinearity:** When independent variables are highly correlated with each other.\n",
    "\n",
    "**Problems:**\n",
    "- Unstable coefficients\n",
    "- Can't isolate individual effects\n",
    "- Unrealistic what-if scenarios\n",
    "\n",
    "**Detection:** Correlation matrix and VIF (Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec26eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features for correlation analysis\n",
    "numeric_cols = ['sqft', 'bedrooms', 'bathrooms', 'age_years', 'garage_spaces', \n",
    "                'condition', 'has_pool_binary', 'location_Suburban', 'location_Urban', 'price_usd']\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df_encoded[numeric_cols].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlGn', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix: Checking for Multicollinearity', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify high correlations (excluding target)\n",
    "print(\"\\n‚ö†Ô∏è Checking for Multicollinearity (|correlation| > 0.7):\\n\")\n",
    "feature_cols = [col for col in numeric_cols if col != 'price_usd']\n",
    "found_issues = False\n",
    "\n",
    "for i, col1 in enumerate(feature_cols):\n",
    "    for col2 in feature_cols[i+1:]:\n",
    "        corr_val = corr_matrix.loc[col1, col2]\n",
    "        if abs(corr_val) > 0.7:\n",
    "            print(f\"   ‚ö†Ô∏è {col1:20s} ‚Üî {col2:20s}: {corr_val:+.3f}\")\n",
    "            found_issues = True\n",
    "\n",
    "if not found_issues:\n",
    "    print(\"   ‚úÖ No severe multicollinearity detected!\")\n",
    "\n",
    "# Show correlations with target\n",
    "print(\"\\n\\nüìä Correlations with Target (price_usd):\\n\")\n",
    "target_corr = corr_matrix['price_usd'].sort_values(ascending=False)\n",
    "for feature, corr in target_corr.items():\n",
    "    if feature != 'price_usd':\n",
    "        strength = 'Strong' if abs(corr) > 0.7 else 'Moderate' if abs(corr) > 0.4 else 'Weak'\n",
    "        print(f\"   {feature:20s}: {corr:+.3f} ({strength})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4de11",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Concept 3: Building Multiple Linear Regression Model\n",
    "\n",
    "**Equation:**\n",
    "$$\\text{Price} = \\theta_0 + \\theta_1 \\times \\text{sqft} + \\theta_2 \\times \\text{bedrooms} + ... + \\theta_n \\times \\text{feature}_n$$\n",
    "\n",
    "**Matrix Form:**\n",
    "$$\\hat{y} = X\\theta$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e8a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_columns = ['sqft', 'bedrooms', 'bathrooms', 'age_years', 'garage_spaces', \n",
    "                   'condition', 'has_pool_binary', 'location_Suburban', 'location_Urban']\n",
    "\n",
    "X = df_encoded[feature_columns]\n",
    "y = df_encoded['price_usd']\n",
    "\n",
    "# Split into train/test sets (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"üìä Dataset Split:\")\n",
    "print(f\"   Training set: {X_train.shape[0]} houses ({X_train.shape[0]/len(df)*100:.0f}%)\")\n",
    "print(f\"   Test set:     {X_test.shape[0]} houses ({X_test.shape[0]/len(df)*100:.0f}%)\")\n",
    "print(f\"   Features:     {X_train.shape[1]}\")\n",
    "\n",
    "# Display feature matrix structure\n",
    "print(\"\\n\\nüîç Feature Matrix (X) - First 5 rows:\")\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"\\n\\nüéØ Target Vector (y) - First 5 values:\")\n",
    "print(y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b9bef",
   "metadata": {},
   "source": [
    "## üßÆ Method 1: Ordinary Least Squares (OLS)\n",
    "\n",
    "**Formula:** $\\theta = (X^T X)^{-1} X^T y$\n",
    "\n",
    "**Characteristics:**\n",
    "- ‚úÖ Exact solution (closed-form)\n",
    "- ‚úÖ Fast for small/medium datasets\n",
    "- ‚ùå Computationally expensive for large data (matrix inversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16955390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using OLS (default in sklearn)\n",
    "model_ols = LinearRegression()\n",
    "model_ols.fit(X_train, y_train)\n",
    "\n",
    "# Extract parameters\n",
    "intercept = model_ols.intercept_\n",
    "coefficients = model_ols.coef_\n",
    "\n",
    "print(\"üèóÔ∏è Multiple Linear Regression Model (OLS)\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìê Equation:\\n\")\n",
    "print(f\"   Price = {intercept:,.2f}\")\n",
    "for feature, coef in zip(feature_columns, coefficients):\n",
    "    print(f\"         {coef:+,.2f} √ó {feature}\")\n",
    "\n",
    "print(f\"\\n\\nüí° Coefficient Interpretation:\\n\")\n",
    "for feature, coef in zip(feature_columns, coefficients):\n",
    "    if coef > 0:\n",
    "        print(f\"   ‚ÜóÔ∏è {feature:20s}: Each unit increases price by ${abs(coef):,.2f}\")\n",
    "    else:\n",
    "        print(f\"   ‚ÜòÔ∏è {feature:20s}: Each unit decreases price by ${abs(coef):,.2f}\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_ols = model_ols.predict(X_train)\n",
    "y_pred_test_ols = model_ols.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2_train = r2_score(y_train, y_pred_train_ols)\n",
    "r2_test = r2_score(y_test, y_pred_test_ols)\n",
    "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train_ols))\n",
    "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test_ols))\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train_ols)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test_ols)\n",
    "\n",
    "print(f\"\\n\\nüìä Model Performance (OLS):\\n\")\n",
    "print(f\"   Training Set:\")\n",
    "print(f\"     R¬≤:   {r2_train:.4f} ({r2_train*100:.2f}% variance explained)\")\n",
    "print(f\"     RMSE: ${rmse_train:,.2f}\")\n",
    "print(f\"     MAE:  ${mae_train:,.2f}\")\n",
    "print(f\"\\n   Test Set:\")\n",
    "print(f\"     R¬≤:   {r2_test:.4f} ({r2_test*100:.2f}% variance explained)\")\n",
    "print(f\"     RMSE: ${rmse_test:,.2f}\")\n",
    "print(f\"     MAE:  ${mae_test:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c88eb6d",
   "metadata": {},
   "source": [
    "## üèÉ Method 2: Gradient Descent\n",
    "\n",
    "**Approach:** Iteratively update weights to minimize error\n",
    "\n",
    "**Formula:** $\\theta = \\theta - \\alpha \\nabla MSE$\n",
    "\n",
    "**Characteristics:**\n",
    "- ‚úÖ Scales to large datasets\n",
    "- ‚úÖ More robust to multicollinearity\n",
    "- ‚ùå Approximate solution\n",
    "- ‚ùå Requires hyperparameter tuning (learning rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6660c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Descent requires feature scaling!\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train model using SGD (Stochastic Gradient Descent)\n",
    "model_gd = SGDRegressor(max_iter=1000, learning_rate='constant', eta0=0.01, random_state=42)\n",
    "model_gd.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Extract parameters\n",
    "intercept_gd = model_gd.intercept_[0]\n",
    "coefficients_gd = model_gd.coef_\n",
    "\n",
    "print(\"üèÉ Multiple Linear Regression Model (Gradient Descent)\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìê Equation (on scaled features):\\n\")\n",
    "print(f\"   Price = {intercept_gd:,.2f}\")\n",
    "for feature, coef in zip(feature_columns, coefficients_gd):\n",
    "    print(f\"         {coef:+,.2f} √ó {feature}_scaled\")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train_gd = model_gd.predict(X_train_scaled)\n",
    "y_pred_test_gd = model_gd.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate\n",
    "r2_train_gd = r2_score(y_train, y_pred_train_gd)\n",
    "r2_test_gd = r2_score(y_test, y_pred_test_gd)\n",
    "rmse_train_gd = np.sqrt(mean_squared_error(y_train, y_pred_train_gd))\n",
    "rmse_test_gd = np.sqrt(mean_squared_error(y_test, y_pred_test_gd))\n",
    "mae_train_gd = mean_absolute_error(y_train, y_pred_train_gd)\n",
    "mae_test_gd = mean_absolute_error(y_test, y_pred_test_gd)\n",
    "\n",
    "print(f\"\\n\\nüìä Model Performance (Gradient Descent):\\n\")\n",
    "print(f\"   Training Set:\")\n",
    "print(f\"     R¬≤:   {r2_train_gd:.4f} ({r2_train_gd*100:.2f}% variance explained)\")\n",
    "print(f\"     RMSE: ${rmse_train_gd:,.2f}\")\n",
    "print(f\"     MAE:  ${mae_train_gd:,.2f}\")\n",
    "print(f\"\\n   Test Set:\")\n",
    "print(f\"     R¬≤:   {r2_test_gd:.4f} ({r2_test_gd*100:.2f}% variance explained)\")\n",
    "print(f\"     RMSE: ${rmse_test_gd:,.2f}\")\n",
    "print(f\"     MAE:  ${mae_test_gd:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4979d",
   "metadata": {},
   "source": [
    "## üÜö Comparing OLS vs Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39abe7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['Training R¬≤', 'Test R¬≤', 'Training RMSE', 'Test RMSE', 'Training MAE', 'Test MAE'],\n",
    "    'OLS': [\n",
    "        f\"{r2_train:.4f}\",\n",
    "        f\"{r2_test:.4f}\",\n",
    "        f\"${rmse_train:,.2f}\",\n",
    "        f\"${rmse_test:,.2f}\",\n",
    "        f\"${mae_train:,.2f}\",\n",
    "        f\"${mae_test:,.2f}\"\n",
    "    ],\n",
    "    'Gradient Descent': [\n",
    "        f\"{r2_train_gd:.4f}\",\n",
    "        f\"{r2_test_gd:.4f}\",\n",
    "        f\"${rmse_train_gd:,.2f}\",\n",
    "        f\"${rmse_test_gd:,.2f}\",\n",
    "        f\"${mae_train_gd:,.2f}\",\n",
    "        f\"${mae_test_gd:,.2f}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n‚öñÔ∏è OLS vs Gradient Descent Comparison:\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# OLS\n",
    "axes[0].scatter(y_test, y_pred_test_ols, alpha=0.6, s=50)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[0].set_xlabel('Actual Price (USD)', fontsize=12)\n",
    "axes[0].set_ylabel('Predicted Price (USD)', fontsize=12)\n",
    "axes[0].set_title(f'OLS (R¬≤={r2_test:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Gradient Descent\n",
    "axes[1].scatter(y_test, y_pred_test_gd, alpha=0.6, s=50, color='green')\n",
    "axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', linewidth=2, label='Perfect Prediction')\n",
    "axes[1].set_xlabel('Actual Price (USD)', fontsize=12)\n",
    "axes[1].set_ylabel('Predicted Price (USD)', fontsize=12)\n",
    "axes[1].set_title(f'Gradient Descent (R¬≤={r2_test_gd:.4f})', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüí° Key Insight:\")\n",
    "print(\"   Both methods produce similar results on this dataset!\")\n",
    "print(\"   OLS is slightly better for small data; GD scales better to large data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5608ca61",
   "metadata": {},
   "source": [
    "## üìä Visualizing 3D Regression Plane\n",
    "\n",
    "For 2 features, regression creates a **plane** in 3D space.\n",
    "For 3+ features, it creates a **hyperplane** (can't visualize directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b1527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build simple model with only 2 features for visualization\n",
    "X_viz = df_encoded[['sqft', 'bedrooms']]\n",
    "y_viz = df_encoded['price_usd']\n",
    "\n",
    "model_viz = LinearRegression()\n",
    "model_viz.fit(X_viz, y_viz)\n",
    "\n",
    "# Create mesh grid\n",
    "sqft_range = np.linspace(df_encoded['sqft'].min(), df_encoded['sqft'].max(), 20)\n",
    "bedrooms_range = np.linspace(df_encoded['bedrooms'].min(), df_encoded['bedrooms'].max(), 20)\n",
    "sqft_grid, bedrooms_grid = np.meshgrid(sqft_range, bedrooms_range)\n",
    "\n",
    "# Predict prices for grid\n",
    "X_grid = np.c_[sqft_grid.ravel(), bedrooms_grid.ravel()]\n",
    "price_grid = model_viz.predict(X_grid).reshape(sqft_grid.shape)\n",
    "\n",
    "# 3D plot\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Scatter plot of actual data\n",
    "ax.scatter(df_encoded['sqft'], df_encoded['bedrooms'], df_encoded['price_usd'], \n",
    "           c='red', marker='o', s=30, alpha=0.6, label='Actual Houses')\n",
    "\n",
    "# Surface plot of regression plane\n",
    "ax.plot_surface(sqft_grid, bedrooms_grid, price_grid, alpha=0.3, cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('Square Feet', fontsize=12)\n",
    "ax.set_ylabel('Bedrooms', fontsize=12)\n",
    "ax.set_zlabel('Price (USD)', fontsize=12)\n",
    "ax.set_title('3D Regression Plane: Price ~ SqFt + Bedrooms', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìê Equation (2D plane):\")\n",
    "print(f\"   Price = {model_viz.intercept_:,.2f} + {model_viz.coef_[0]:,.2f}√óSqFt + {model_viz.coef_[1]:,.2f}√óBedrooms\")\n",
    "print(\"\\nüí° With 3+ features, we get a HYPERPLANE (can't visualize, but same concept!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba78ef5",
   "metadata": {},
   "source": [
    "## üîÆ Concept 4: What-If Scenario Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0036c7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario: Renovating a house - what's the ROI?\n",
    "print(\"üè° What-If Scenario: House Renovation Analysis\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Baseline house\n",
    "baseline = pd.DataFrame({\n",
    "    'sqft': [2000],\n",
    "    'bedrooms': [3],\n",
    "    'bathrooms': [2],\n",
    "    'age_years': [20],\n",
    "    'garage_spaces': [1],\n",
    "    'condition': [6],\n",
    "    'has_pool_binary': [0],\n",
    "    'location_Suburban': [1],\n",
    "    'location_Urban': [0]\n",
    "})\n",
    "\n",
    "baseline_price = model_ols.predict(baseline)[0]\n",
    "print(f\"\\nüè† Baseline House:\")\n",
    "print(f\"   2,000 sqft, 3 bed, 2 bath, 20 years old, 1 garage, condition=6\")\n",
    "print(f\"   Suburban, No pool\")\n",
    "print(f\"   Predicted Price: ${baseline_price:,.2f}\")\n",
    "\n",
    "# Scenario 1: Add a pool\n",
    "with_pool = baseline.copy()\n",
    "with_pool['has_pool_binary'] = 1\n",
    "pool_price = model_ols.predict(with_pool)[0]\n",
    "pool_roi = pool_price - baseline_price\n",
    "\n",
    "print(f\"\\n\\nüíß Scenario 1: Add Swimming Pool\")\n",
    "print(f\"   New Price: ${pool_price:,.2f}\")\n",
    "print(f\"   Price Increase: ${pool_roi:,.2f}\")\n",
    "print(f\"   ROI: {(pool_roi/baseline_price)*100:.1f}%\")\n",
    "\n",
    "# Scenario 2: Renovate (improve condition from 6 to 9)\n",
    "renovated = baseline.copy()\n",
    "renovated['condition'] = 9\n",
    "renovated_price = model_ols.predict(renovated)[0]\n",
    "renovation_roi = renovated_price - baseline_price\n",
    "\n",
    "print(f\"\\n\\nüî® Scenario 2: Full Renovation (condition 6‚Üí9)\")\n",
    "print(f\"   New Price: ${renovated_price:,.2f}\")\n",
    "print(f\"   Price Increase: ${renovation_roi:,.2f}\")\n",
    "print(f\"   ROI: {(renovation_roi/baseline_price)*100:.1f}%\")\n",
    "\n",
    "# Scenario 3: Add garage space\n",
    "with_garage = baseline.copy()\n",
    "with_garage['garage_spaces'] = 2\n",
    "garage_price = model_ols.predict(with_garage)[0]\n",
    "garage_roi = garage_price - baseline_price\n",
    "\n",
    "print(f\"\\n\\nüöó Scenario 3: Add Garage Space (1‚Üí2 cars)\")\n",
    "print(f\"   New Price: ${garage_price:,.2f}\")\n",
    "print(f\"   Price Increase: ${garage_roi:,.2f}\")\n",
    "print(f\"   ROI: {(garage_roi/baseline_price)*100:.1f}%\")\n",
    "\n",
    "# Comparison\n",
    "print(f\"\\n\\n\" + \"=\"*70)\n",
    "print(f\"\\nüèÜ Best ROI: \", end=\"\")\n",
    "max_roi = max(pool_roi, renovation_roi, garage_roi)\n",
    "if max_roi == pool_roi:\n",
    "    print(f\"Add Pool (${pool_roi:,.2f})\")\n",
    "elif max_roi == renovation_roi:\n",
    "    print(f\"Renovation (${renovation_roi:,.2f})\")\n",
    "else:\n",
    "    print(f\"Add Garage (${garage_roi:,.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c8dba4",
   "metadata": {},
   "source": [
    "## üìä Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Coefficient': coefficients,\n",
    "    'Abs_Coefficient': np.abs(coefficients)\n",
    "}).sort_values('Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nüìä Feature Importance (by coefficient magnitude):\\n\")\n",
    "print(feature_importance[['Feature', 'Coefficient']].to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in feature_importance['Coefficient']]\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Coefficient'], color=colors, alpha=0.7)\n",
    "plt.xlabel('Coefficient Value ($ impact)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance: Impact on House Price', fontsize=14, fontweight='bold')\n",
    "plt.axvline(0, color='black', linewidth=1)\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n\\nüí° Top 3 Most Important Features:\")\n",
    "for i, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"   {i+1}. {row['Feature']:20s}: ${abs(row['Coefficient']):,.2f} per unit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412846b",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 1: Predict Price for New House"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f83d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# New house specs:\n",
    "# - 2,500 sqft\n",
    "# - 4 bedrooms\n",
    "# - 2.5 bathrooms\n",
    "# - 5 years old\n",
    "# - 2 garage spaces\n",
    "# - Condition: 8\n",
    "# - Urban location\n",
    "# - Has pool\n",
    "\n",
    "new_house = pd.DataFrame({\n",
    "    'sqft': [2500],\n",
    "    'bedrooms': [4],\n",
    "    'bathrooms': [2.5],\n",
    "    'age_years': [5],\n",
    "    'garage_spaces': [2],\n",
    "    'condition': [8],\n",
    "    'has_pool_binary': [1],\n",
    "    'location_Suburban': [0],\n",
    "    'location_Urban': [1]\n",
    "})\n",
    "\n",
    "predicted_price = model_ols.predict(new_house)[0]\n",
    "\n",
    "print(f\"\\nüè† New House Prediction:\")\n",
    "print(f\"   Predicted Price: ${predicted_price:,.2f}\")\n",
    "print(f\"   Recommended listing range: ${predicted_price*0.97:,.2f} - ${predicted_price*1.03:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515efef",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 2: Multicollinearity Challenge\n",
    "\n",
    "**Task:** Add a highly correlated feature (price per sqft) and observe the impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47367b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Create a new feature: price_per_sqft = price_usd / sqft\n",
    "# Add it to the model and compare results\n",
    "\n",
    "df_multicollinear = df_encoded.copy()\n",
    "df_multicollinear['price_per_sqft'] = df_multicollinear['price_usd'] / df_multicollinear['sqft']\n",
    "\n",
    "# Add to features\n",
    "feature_columns_mc = feature_columns + ['price_per_sqft']\n",
    "X_mc = df_multicollinear[feature_columns_mc]\n",
    "y_mc = df_multicollinear['price_usd']\n",
    "\n",
    "# Split and train\n",
    "X_train_mc, X_test_mc, y_train_mc, y_test_mc = train_test_split(X_mc, y_mc, test_size=0.2, random_state=42)\n",
    "model_mc = LinearRegression()\n",
    "model_mc.fit(X_train_mc, y_train_mc)\n",
    "\n",
    "# Compare coefficients\n",
    "print(\"\\n‚ö†Ô∏è Multicollinearity Impact:\\n\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Original_Coef': coefficients,\n",
    "    'With_Multicollinear_Coef': model_mc.coef_[:len(feature_columns)],\n",
    "    'Change': model_mc.coef_[:len(feature_columns)] - coefficients\n",
    "})\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\nüí° Notice how coefficients became UNSTABLE when we added price_per_sqft!\")\n",
    "print(f\"   This is because price_per_sqft is perfectly correlated with price (it's derived from it).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5504fd",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercise 3: Identify Best Value Houses\n",
    "\n",
    "**Task:** Find houses where actual price is significantly lower than predicted (good deals!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae0cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Calculate residuals and find top 10 underpriced houses\n",
    "\n",
    "df_analysis = df_encoded.copy()\n",
    "df_analysis['predicted_price'] = model_ols.predict(X)\n",
    "df_analysis['residual'] = df_analysis['price_usd'] - df_analysis['predicted_price']\n",
    "df_analysis['value_score'] = df_analysis['residual'] / df_analysis['predicted_price'] * 100\n",
    "\n",
    "# Top 10 best deals (actual < predicted)\n",
    "best_deals = df_analysis.nsmallest(10, 'residual')[[\n",
    "    'house_id', 'sqft', 'bedrooms', 'location', 'price_usd', 'predicted_price', 'residual', 'value_score'\n",
    "]]\n",
    "\n",
    "print(\"\\nüî• Top 10 Best Value Houses (Underpriced):\\n\")\n",
    "print(best_deals.to_string(index=False))\n",
    "\n",
    "print(f\"\\n\\nüí° Interpretation:\")\n",
    "print(f\"   Negative residual = Actual price LOWER than predicted\")\n",
    "print(f\"   These are potential great deals for buyers!\")\n",
    "print(f\"   Sellers might be motivated or house needs minor repairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbb38e7",
   "metadata": {},
   "source": [
    "## üìö Key Concepts Summary\n",
    "\n",
    "### What You Learned:\n",
    "\n",
    "1. **‚úÖ Multiple Linear Regression**\n",
    "   - Uses 2+ features for better predictions\n",
    "   - Equation: $\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... + \\theta_n x_n$\n",
    "   - Matrix form: $\\hat{y} = X\\theta$\n",
    "\n",
    "2. **‚úÖ Handling Categorical Variables**\n",
    "   - Binary encoding for 2 categories (0/1)\n",
    "   - One-hot encoding for 3+ categories\n",
    "   - Drop one category to avoid dummy variable trap\n",
    "\n",
    "3. **‚úÖ Multicollinearity**\n",
    "   - When features are highly correlated\n",
    "   - Causes unstable coefficients\n",
    "   - Detect with correlation matrix and VIF\n",
    "   - Solution: Remove redundant features\n",
    "\n",
    "4. **‚úÖ Estimation Methods**\n",
    "   - **OLS:** Exact, fast for small data, matrix-based\n",
    "   - **Gradient Descent:** Iterative, scales to large data, requires scaling\n",
    "\n",
    "5. **‚úÖ Visualization**\n",
    "   - 2 features ‚Üí plane (3D)\n",
    "   - 3+ features ‚Üí hyperplane (can't visualize)\n",
    "\n",
    "6. **‚úÖ What-If Scenarios**\n",
    "   - Predict impact of changes\n",
    "   - Calculate ROI for renovations\n",
    "   - Must respect feature correlations\n",
    "\n",
    "7. **‚úÖ Feature Importance**\n",
    "   - Coefficient magnitude shows impact\n",
    "   - Positive = increases target\n",
    "   - Negative = decreases target\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've mastered **Multiple Linear Regression**!\n",
    "\n",
    "**Next Steps:**\n",
    "- ‚úÖ Learn about polynomial regression (curved relationships)\n",
    "- ‚úÖ Explore regularization (Ridge, Lasso) to prevent overfitting\n",
    "- ‚úÖ Practice feature engineering\n",
    "- ‚úÖ Study logistic regression (classification)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4822365",
   "metadata": {},
   "source": [
    "## üì¶ Library Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6810ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document versions for reproducibility\n",
    "import sys\n",
    "import sklearn\n",
    "\n",
    "print(\"Library Versions:\")\n",
    "print(f\"  Python: {sys.version}\")\n",
    "print(f\"  NumPy: {np.__version__}\")\n",
    "print(f\"  Pandas: {pd.__version__}\")\n",
    "print(f\"  Matplotlib: {plt.matplotlib.__version__}\")\n",
    "print(f\"  Seaborn: {sns.__version__}\")\n",
    "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"\\nRandom Seed: 42\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
